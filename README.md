# NLP-with-BERT 

We perform semantic analysis on movie reviews using data from one of the most visited websites in the world: IMDB i.e., we perform semantic analysis on a large dataset of movie reviews using the low-code Python library, Ktrain.

Why is BERT so revolutionary?

Not only is it a framework that has been pre-trained with the biggest data set ever used, it is also remarkably easy to adapt to different NLP applications, by adding additional output layers. This allows users to create sophisticated and precise models to carry out a wide variety of NLP tasks.

Steps:

Part 1: Data Preprocessing

    Loading the IMDB dataset

    Creating the training and test sets

Part 2: Building the BERT model

Part 3: Training and evaluating the BERT model

    Getting the learner instance

    Training and evaluating the BERT model
Thank you!
